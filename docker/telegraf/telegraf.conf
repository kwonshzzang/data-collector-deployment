# Configuration for telegraf agent
[agent]
  ## Default data collection interval for all inputs
  interval = "10s"
  ## Rounds collection interval to 'interval'
  ## ie, if interval="10s" then always collect on :00, :10, :20, etc.
  round_interval = true

  ## Default flushing interval for all outputs. Maximum flush_interval will be
  ## flush_interval + flush_jitter
  flush_interval = "10s"
  ## Jitter the flush interval by a random amount. This is primarily to avoid
  ## large write spikes for users running a large number of telegraf instances.
  ## ie, a jitter of 5s and interval 10s means flushes will happen every 10-15s
  flush_jitter = "0s"

  ## Log at debug level.
  debug = true
  ## Override default hostname, if empty use os.Hostname()
  # hostname = ""
  ## If set to true, do no set the "host" tag in the telegraf agent.
  omit_hostname = true

  ## Flag to skip running processors after aggregators
  ## By default, processors are run a second time after aggregators. Changing
  ## this setting to true will skip the second run of processors.
  skip_processors_after_aggregators = true

# Configuration for sending metrics to InfluxDB 2.0
[[outputs.influxdb_v2]]
  urls = ["http://influxdb:8086"]
  ## Token for authentication.
  token = "MyInitialAdminToken0=="
  ## Organization is the name of the organization you wish to write to.
  organization = "docs"
  ## Destination bucket to write into.
  bucket = "my-database"

[[inputs.kafka_consumer]]
  ## Kafka brokers.
  brokers = ["broker:29092"]

   ## Topics to consume.
  topics = ["weather-observation"]

   ## Maximum length of a message to consume, in bytes (default 0/unlimited);
  ## larger messages are dropped
  max_message_len = 1000000

  ## Avro data format settings
  data_format = "avro"

  ## Url of the schema registry; exactly one of schema registry and
  ## schema must be set
  avro_schema_registry = "http://schema-registry:8081"

  ## Measurement string; if not set, determine measurement name from
  ## schema (as "<namespace>.<name>")
  avro_measurement = "weather-observation"

  ## Avro fields to be used as tags; optional.
  avro_tags = ["base_date", "base_time", "category", "nx", "ny"]

  ## Avro fields to be used as fields; if empty, any Avro fields
  ## detected from the schema, not used as tags, will be used as
  ## measurement fields.
  avro_fields = ["obsr_value"]

[[inputs.kafka_consumer]]
  ## Kafka brokers.
  brokers = ["broker:29092"]

   ## Topics to consume.
  topics = ["weather-prediction"]

   ## Maximum length of a message to consume, in bytes (default 0/unlimited);
  ## larger messages are dropped
  max_message_len = 1000000

  ## Avro data format settings
  data_format = "avro"

  ## Url of the schema registry; exactly one of schema registry and
  ## schema must be set
  avro_schema_registry = "http://schema-registry:8081"

  ## Measurement string; if not set, determine measurement name from
  ## schema (as "<namespace>.<name>")
  avro_measurement = "weather-prediction"

  ## Avro fields to be used as tags; optional.
  avro_tags = ["base_date", "base_time", "fcst_date", "fcst_time", "category", "nx", "ny"]

  ## Avro fields to be used as fields; if empty, any Avro fields
  ## detected from the schema, not used as tags, will be used as
  ## measurement fields.
  avro_fields = ["fcst_value"]

[[inputs.kafka_consumer]]
  ## Kafka brokers.
  brokers = ["broker:29092"]

   ## Topics to consume.
  topics = ["sensor-data"]

   ## Maximum length of a message to consume, in bytes (default 0/unlimited);
  ## larger messages are dropped
  max_message_len = 1000000

  ## Avro data format settings
  data_format = "avro"

  ## Url of the schema registry; exactly one of schema registry and
  ## schema must be set
  avro_schema_registry = "http://schema-registry:8081"

  ## Measurement string; if not set, determine measurement name from
  ## schema (as "<namespace>.<name>")
  avro_measurement = "sensor-data"

  ## Avro fields to be used as tags; optional.
  avro_tags = ["sensor_id",  "data_type", "status"]

  ## Avro fields to be used as fields; if empty, any Avro fields
  ## detected from the schema, not used as tags, will be used as
  ## measurement fields.
  avro_fields = ["value"]
